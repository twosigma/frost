#!/usr/bin/env python3

#    Copyright 2026 Two Sigma Open Source, LLC
#
#    Licensed under the Apache License, Version 2.0 (the "License");
#    you may not use this file except in compliance with the License.
#    You may obtain a copy of the License at
#
#        http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS,
#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#    See the License for the specific language governing permissions and
#    limitations under the License.

"""Run RISC-V Architecture Tests (riscv-arch-test) on Frost.

Orchestrates building, simulating, and comparing signatures for
riscv-arch-test compliance tests against golden reference outputs.

Can be run standalone:
    ./test_arch_compliance.py --sim verilator --extensions I M
    ./test_arch_compliance.py --sim verilator --all
    ./test_arch_compliance.py --sim verilator --test rv32i_m/I/src/add-01.S
    ./test_arch_compliance.py --sim verilator --extensions I --parallel 4

Or via pytest:
    pytest test_arch_compliance.py -v --sim verilator -m slow
"""

import argparse
import os
import subprocess
import sys
from concurrent.futures import ProcessPoolExecutor, as_completed
from dataclasses import dataclass
from pathlib import Path
from typing import Any

import pytest

from test_run_cocotb import CocotbRunner

# Directory layout
TESTS_DIR = Path(__file__).parent.resolve()
REPO_ROOT = TESTS_DIR.parent
ARCH_TEST_APP_DIR = REPO_ROOT / "sw" / "apps" / "arch_test"
ARCH_TEST_DIR = ARCH_TEST_APP_DIR / "riscv-arch-test"
SUITE_DIR = ARCH_TEST_DIR / "riscv-test-suite" / "rv32i_m"
REFERENCES_DIR = ARCH_TEST_APP_DIR / "references"

# Extensions available in the test suite (dev branch) relevant to Frost's ISA
SUPPORTED_EXTENSIONS = [
    "I",
    "M",
    "A",
    "F",
    "D",
    "C",
    "B",
    "K",
    "Zicond",
    "Zifencei",
    "privilege",
    "F_Zcf",
    "D_Zcd",
    "hints",
]

# Filter for extensions where Frost only implements a subset of instructions.
# Maps extension name -> set of test filename prefixes to include.
# Extensions not listed here run all their tests.
# Frost implements Zbkb (pack, packh, brev8, zip, unzip) from the K extension
# but not Zbkx (xperm4/xperm8), Zkn (AES/SHA256/SHA512), or Zks (SM3/SM4).
# Frost is M-mode only (no S/U mode), so privilege tests are filtered
# to exclude supervisor, user, and hypervisor tests.
EXTENSION_TEST_FILTERS: dict[str, set[str]] = {
    "K": {"pack", "packh", "brev8", "zip", "unzip"},
    "privilege": {"ebreak", "ecall", "misalign", "menvcfg_m"},
}

# Maximum test case count for simulation. Tests with more than this many
# inst_ entries are too slow for Verilator simulation (>30 min each) and
# should be validated on hardware instead. The 12 excluded tests all have
# 7000+ cases; the largest passing test has ~2300.
# Override with --no-sim-filter (CLI) or include_all=True (API).
SIM_MAX_TEST_CASES = 5000


@dataclass
class TestResult:
    """Result of a single architecture test."""

    test_name: str
    extension: str
    status: str  # "PASS", "FAIL", "SKIP"
    message: str = ""


def _count_test_cases(test_src: Path) -> int:
    """Count inst_ labels in a test file (proxy for test case count)."""
    count = 0
    with open(test_src) as f:
        for line in f:
            if line.startswith("inst_"):
                count += 1
    return count


def discover_tests(extension: str, include_all: bool = False) -> list[Path]:
    """Find all .S test files for an extension.

    If the extension has a filter in EXTENSION_TEST_FILTERS, only tests whose
    filename (without numeric suffix) matches a filter prefix are returned.

    Unless include_all is True, tests exceeding SIM_MAX_TEST_CASES are excluded
    (too slow for simulation, should be validated on hardware).
    """
    src_dir = SUITE_DIR / extension / "src"
    if not src_dir.is_dir():
        return []
    tests = sorted(src_dir.glob("*.S"))
    allowed_prefixes = EXTENSION_TEST_FILTERS.get(extension)
    if allowed_prefixes is not None:
        tests = [
            t
            for t in tests
            if any(t.stem.startswith(prefix) for prefix in allowed_prefixes)
        ]
    if not include_all:
        filtered = []
        for t in tests:
            count = _count_test_cases(t)
            if count > SIM_MAX_TEST_CASES:
                print(
                    f"  Skipping {t.stem} ({count} test cases > {SIM_MAX_TEST_CASES} limit)"
                )
            else:
                filtered.append(t)
        tests = filtered
    return tests


def get_reference_path(test_src: Path) -> Path:
    """Get the golden reference output path for a test source file.

    References are stored locally in references/{extension}/{test}.reference_output,
    generated by generate_references.py using Spike.
    """
    # Extract extension name from path: .../rv32i_m/{EXT}/src/{test}.S
    ext_name = test_src.parent.parent.name
    test_stem = test_src.stem
    return REFERENCES_DIR / ext_name / f"{test_stem}.reference_output"


def compile_test(test_src: Path) -> bool:
    """Compile a single arch test, returns True on success."""
    result = subprocess.run(
        ["make", "clean"],
        cwd=ARCH_TEST_APP_DIR,
        capture_output=True,
        text=True,
        timeout=30,
    )

    rel_src = test_src.relative_to(ARCH_TEST_APP_DIR)
    result = subprocess.run(
        ["make", f"TEST_SRC={rel_src}"],
        cwd=ARCH_TEST_APP_DIR,
        capture_output=True,
        text=True,
        timeout=120,
    )
    return result.returncode == 0


def run_simulation(simulator: str) -> subprocess.CompletedProcess[str] | None:
    """Run cocotb simulation and return the result."""
    runner = CocotbRunner(
        python_test_module="cocotb_tests.test_real_program",
        hdl_toplevel_module="frost",
        app_name=None,  # We handle compilation ourselves
    )

    # Set up the sw.mem symlink manually
    os.environ["SIM"] = simulator
    env = runner.setup_environment()
    sim_build_dir = runner._get_sim_build_dir(env)
    env["SIM_BUILD"] = str(sim_build_dir)
    # Arch tests with many test vectors need more cycles than the default 500K.
    # The fmadd/fmsub/fnmadd/fnmsub tests have ~14K test cases each, and
    # double-precision b11 tests have ~11K cases, needing well over 5M cycles.
    env["COCOTB_MAX_CYCLES"] = "50000000"

    original_dir = os.getcwd()
    os.chdir(TESTS_DIR)

    try:
        # Clean only if Verilator toplevel changed
        needs_clean = simulator != "verilator" or runner._verilator_needs_rebuild(
            sim_build_dir
        )
        if needs_clean:
            subprocess.run(["make", "clean"], check=False)

        # Set up sw.mem symlink pointing to our compiled test
        sw_mem_path = Path("sw.mem")
        if sw_mem_path.exists() or sw_mem_path.is_symlink():
            sw_mem_path.unlink()
        sw_mem_target = ARCH_TEST_APP_DIR / "sw.mem"
        sw_mem_path.symlink_to(sw_mem_target)

        # Run simulation
        pythonpath = env.get("PYTHONPATH", "")
        cmd = (
            f"export PYTHONPATH='{pythonpath}' && "
            f"make COCOTB_TEST_MODULES='cocotb_tests.test_real_program' "
            f"TOPLEVEL=frost"
        )
        result = subprocess.run(
            ["bash", "-c", cmd],
            capture_output=True,
            text=True,
            env=env,
            check=False,
            timeout=7200,
        )

        if simulator == "verilator" and result.returncode == 0:
            runner._update_verilator_toplevel_marker(sim_build_dir)

        return result

    except subprocess.TimeoutExpired:
        return None
    finally:
        sw_mem_path = Path("sw.mem")
        if sw_mem_path.exists() or sw_mem_path.is_symlink():
            sw_mem_path.unlink()
        os.chdir(original_dir)


def extract_signature(sim_output: str) -> list[str]:
    """Extract hex signature lines from simulation UART output.

    The RVMODEL_HALT macro prints each signature word as 8 lowercase hex
    characters followed by a newline, then <<PASS>>.

    We collect all 8-char hex lines that appear immediately before a
    standalone <<PASS>> marker (one that starts the line, not embedded in
    a log message like "success_marker=<<PASS>>").
    """
    lines = sim_output.splitlines()
    sig_lines: list[str] = []
    collecting = False
    for line in lines:
        stripped = line.strip()
        # Signature lines are exactly 8 hex characters
        if len(stripped) == 8 and all(c in "0123456789abcdefABCDEF" for c in stripped):
            collecting = True
            sig_lines.append(stripped.lower())
        elif collecting and stripped.startswith("<<PASS>>"):
            # Found the PASS marker after collecting signature data - done
            break
        elif collecting and stripped:
            # Non-hex, non-empty line after we started collecting: this run's
            # signature block ended (cocotb log line). Reset for next run.
            sig_lines = []
            collecting = False
    return sig_lines


def load_reference(ref_path: Path) -> list[str]:
    """Load golden reference signature file."""
    lines = []
    for line in ref_path.read_text().splitlines():
        stripped = line.strip()
        if stripped:
            lines.append(stripped.lower())
    return lines


def compare_signatures(actual: list[str], expected: list[str]) -> tuple[bool, str]:
    """Compare actual vs expected signatures, return (match, diff_message)."""
    if actual == expected:
        return True, ""

    diff_lines = []
    max_len = max(len(actual), len(expected))
    for i in range(max_len):
        act = actual[i] if i < len(actual) else "<missing>"
        exp = expected[i] if i < len(expected) else "<missing>"
        if act != exp:
            diff_lines.append(f"  word {i}: got {act}, expected {exp}")
            if len(diff_lines) >= 5:
                diff_lines.append(
                    f"  ... and more (actual={len(actual)} words, expected={len(expected)} words)"
                )
                break

    return False, "\n".join(diff_lines)


def run_single_test(test_src: Path, extension: str, simulator: str) -> TestResult:
    """Build, simulate, and verify a single arch test."""
    test_name = test_src.stem

    # Check for reference file
    ref_path = get_reference_path(test_src)
    if not ref_path.exists():
        return TestResult(test_name, extension, "SKIP", "No reference output")

    # Compile
    if not compile_test(test_src):
        return TestResult(
            test_name, extension, "SKIP", "Compilation failed (may exceed ROM)"
        )

    # Simulate
    result = run_simulation(simulator)
    if result is None:
        return TestResult(test_name, extension, "SKIP", "Simulation timed out")

    combined_output = (result.stdout or "") + (result.stderr or "")

    # Check returncode first: when cocotb hits max cycles, its error message
    # contains the literal '<<PASS>>' string (the marker it was searching for),
    # which would cause a false positive if we checked output text first.
    if result.returncode != 0:
        return TestResult(test_name, extension, "SKIP", "Simulation error")

    if "<<PASS>>" not in combined_output:
        return TestResult(test_name, extension, "FAIL", "No <<PASS>> marker in output")

    # Extract and compare signature
    actual_sig = extract_signature(combined_output)
    if not actual_sig:
        return TestResult(test_name, extension, "FAIL", "No signature data in output")

    expected_sig = load_reference(ref_path)
    match, diff_msg = compare_signatures(actual_sig, expected_sig)

    if match:
        return TestResult(test_name, extension, "PASS")
    else:
        return TestResult(
            test_name, extension, "FAIL", f"Signature mismatch:\n{diff_msg}"
        )


def _run_test_worker(args: tuple[str, str, str, str]) -> TestResult:
    """Worker function for parallel test execution."""
    test_src_str, extension, simulator, arch_test_app_dir_str = args
    # Restore module-level paths in worker process
    global ARCH_TEST_APP_DIR, ARCH_TEST_DIR, SUITE_DIR, REFERENCES_DIR
    ARCH_TEST_APP_DIR = Path(arch_test_app_dir_str)
    ARCH_TEST_DIR = ARCH_TEST_APP_DIR / "riscv-arch-test"
    SUITE_DIR = ARCH_TEST_DIR / "riscv-test-suite" / "rv32i_m"
    REFERENCES_DIR = ARCH_TEST_APP_DIR / "references"

    return run_single_test(Path(test_src_str), extension, simulator)


def run_extension_tests(
    extension: str,
    simulator: str,
    parallel: int = 1,
    include_all: bool = False,
) -> list[TestResult]:
    """Run all tests for a given extension."""
    tests = discover_tests(extension, include_all=include_all)
    if not tests:
        print(f"  No tests found for extension {extension}")
        return []

    print(f"\nExtension: {extension} ({len(tests)} tests)")

    results = []

    if parallel > 1:
        # Parallel execution
        work_items = [
            (str(t), extension, simulator, str(ARCH_TEST_APP_DIR)) for t in tests
        ]
        with ProcessPoolExecutor(max_workers=parallel) as executor:
            futures = {
                executor.submit(_run_test_worker, item): item[0] for item in work_items
            }
            for future in as_completed(futures):
                try:
                    result = future.result()
                except Exception as e:
                    failed_src = futures[future]
                    test_name = Path(failed_src).stem
                    result = TestResult(test_name, extension, "SKIP", str(e))
                results.append(result)
                _print_result(result)
    else:
        # Sequential execution
        for test_src in tests:
            result = run_single_test(test_src, extension, simulator)
            results.append(result)
            _print_result(result)

    return results


def _print_result(result: TestResult) -> None:
    """Print a single test result."""
    status_str = {
        "PASS": "PASS",
        "FAIL": "FAIL",
        "SKIP": "SKIP",
    }[result.status]
    line = f"  {result.test_name:40s} {status_str}"
    if result.message and result.status != "PASS":
        # Show first line of message
        first_line = result.message.split("\n")[0]
        line += f"  ({first_line})"
    print(line)


# =============================================================================
# Pytest Integration
# =============================================================================


@pytest.mark.cocotb
@pytest.mark.slow
class TestArchCompliance:
    """RISC-V Architecture Compliance Tests (riscv-arch-test)."""

    EXTENSIONS = SUPPORTED_EXTENSIONS

    @pytest.mark.parametrize("extension", EXTENSIONS)
    def test_arch_compliance(self, extension: str, request: Any, capsys: Any) -> None:
        """Run arch compliance tests for a single ISA extension.

        Parametrized by extension (not individual test) for manageable pytest output.
        Verilator only - skips for other simulators.
        """
        sim = request.config.getoption("--sim")
        if sim != "verilator":
            pytest.skip("Arch compliance tests require verilator")

        os.environ["SIM"] = "verilator"
        with capsys.disabled():
            print(f"\nRunning arch compliance tests for extension {extension}...")
            results = run_extension_tests(extension, "verilator")

        failed = [r for r in results if r.status == "FAIL"]
        if failed:
            msg = "\n".join(f"  {r.test_name}: {r.message}" for r in failed)
            pytest.fail(f"{len(failed)} arch test(s) failed:\n{msg}")


# =============================================================================
# Standalone CLI
# =============================================================================


def main() -> int:
    """Run RISC-V architecture tests on Frost."""
    parser = argparse.ArgumentParser(
        description="Run RISC-V Architecture Tests on Frost",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog=f"""
Examples:
  %(prog)s --sim verilator --extensions I M
  %(prog)s --sim verilator --all
  %(prog)s --sim verilator --test rv32i_m/I/src/add-01.S
  %(prog)s --sim verilator --extensions I --parallel 4

Available extensions: {', '.join(SUPPORTED_EXTENSIONS)}
""",
    )
    parser.add_argument(
        "--sim",
        required=True,
        choices=["icarus", "verilator"],
        help="Simulator to use",
    )
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--extensions",
        nargs="+",
        metavar="EXT",
        help="Extensions to test (e.g., I M C F)",
    )
    group.add_argument(
        "--all",
        action="store_true",
        help="Run all supported extensions",
    )
    group.add_argument(
        "--test",
        metavar="PATH",
        help="Run a single test (path relative to riscv-test-suite, e.g., rv32i_m/I/src/add-01.S)",
    )
    parser.add_argument(
        "--parallel",
        type=int,
        default=1,
        metavar="N",
        help="Number of parallel test workers (default: 1, sequential)",
    )
    parser.add_argument(
        "--no-sim-filter",
        action="store_true",
        help="Include all tests, even those too large for simulation (>5000 test cases)",
    )

    args = parser.parse_args()

    # Single test mode
    if args.test:
        test_path = SUITE_DIR.parent / args.test
        if not test_path.exists():
            # Also try as path relative to arch_test dir
            test_path = ARCH_TEST_DIR / "riscv-test-suite" / args.test
        if not test_path.exists():
            print(f"Error: Test file not found: {args.test}")
            return 1

        # Determine extension from path
        parts = Path(args.test).parts
        ext = parts[1] if len(parts) > 1 else "unknown"

        print(f"=== RISC-V Architecture Test: {args.test} ===")
        result = run_single_test(test_path, ext, args.sim)
        _print_result(result)
        return 0 if result.status == "PASS" else 1

    # Multi-extension mode
    extensions = SUPPORTED_EXTENSIONS if args.all else args.extensions

    # Validate extensions
    for ext in extensions:
        ext_dir = SUITE_DIR / ext
        if not ext_dir.is_dir():
            print(f"Warning: Extension '{ext}' not found in test suite, skipping")

    print("=" * 60)
    print("RISC-V Architecture Test Results")
    print(f"Simulator: {args.sim}")
    print(f"Extensions: {', '.join(extensions)}")
    print("=" * 60)

    all_results: list[TestResult] = []
    for ext in extensions:
        results = run_extension_tests(
            ext, args.sim, parallel=args.parallel, include_all=args.no_sim_filter
        )
        all_results.extend(results)

    # Summary
    n_pass = sum(1 for r in all_results if r.status == "PASS")
    n_fail = sum(1 for r in all_results if r.status == "FAIL")
    n_skip = sum(1 for r in all_results if r.status == "SKIP")

    print()
    print("=" * 60)
    print(f"Summary: {n_pass} PASS, {n_fail} FAIL, {n_skip} SKIP")
    print("=" * 60)

    # Print failed tests
    failed = [r for r in all_results if r.status == "FAIL"]
    if failed:
        print("\nFailed tests:")
        for r in failed:
            print(f"  [{r.extension}] {r.test_name}")
            if r.message:
                for line in r.message.split("\n"):
                    print(f"    {line}")

    return 1 if n_fail > 0 else 0


if __name__ == "__main__":
    sys.exit(main())
